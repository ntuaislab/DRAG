# OpenAI/CLIP-ViT, choices:
#   ['embeddings', 'encoder_layer_<n>', 'image_embeds']
# â€‹checkpoint:
#   ['openai/clip-vit-large-patch14', 'laion/CLIP-ViT-L-14-laion2B-s32B-b82K']

name: Dinov2Model
checkpoint: facebook/dinov2-base
image_size: 224
preprocess:
  - dinov2_processor: {}
