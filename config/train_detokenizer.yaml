# Specify training parameters.
defaults:
  - dataset: imagenet
  - hydra: default
  - model: CLIP-ViT-B-16
  - local: default
  - _self_

dry_run: False

seed: 3407

dataset:
  portion: public

optimizer:
  name: AdamW
  kwargs:
    lr: 1.0e-3
    # betas: [0.9, 0.95]
    # weight_decay: 5.0e-2

scheduler:
  name: CosineAnnealingLRWarmup
  kwargs:
    warmup_iter: 5000
    T_max: ${max_steps}
    eta_min: .0

checkpoint:
  write_disk: true # deprecated
  top_k: 10
  save_top_k: 1
  every_n_train_steps: 10000

batch_size: 256

model:
  torch_dtype: float32
  split_points: ???

preprocess:
  train: ${model.preprocess}
  validation: ${model.preprocess}

reconstructor:
  use_postprocessor: false
  decoder_embed_dim: 512
  num_layers: 4

position_predictor:
  weight_decay: 1.0e-5

scaling_factor: 1
mask_ratio: 0.0

gradient_clip_algorithm: "norm"
gradient_clip_val: .inf

accumulate_grad_batches: 1
max_steps: 100000
log_every_n_steps: 500
val_check_interval: 10000
